{
    "contents" : "require(data.table)\nrequire(caTools)\n# ==== Read file ============================================\nAdult.data <- fread('adult.data.txt')\nadult <- as.data.frame(Adult.data)\n# Benchmark using majority vote\n# 0.7591904\n# max(table(Adult.data$V15))/nrow(Adult.data)\n\n# ==== Data preparation =====================================\n# Transform char into int\nadultcol <- colnames(adult)\ncharIndex <- sapply(adult, class) == 'character'\nchar_int <- as.data.frame(sapply(names(which(charIndex == T)), # Colnames of factor columns\n                                 function(i) as.integer(as.factor(adult[, i])) - 1 )\n                          )\nIntSet <- cbind(adult[, charIndex == F], char_int)\n\n# Re-order\nIntSet <- IntSet[, adultcol]\n\n# Remove column(s)\nIntSet$V4 <- NULL    # remove education\n\n# Scaling\nscaSet <- scale(IntSet[, 1:(ncol(IntSet)-1)])\ny <- IntSet[, ncol(IntSet)] # To prevent duplicated \"V14\" issue\n\n# Re-combine\nIntSet <- as.data.frame(cbind(scaSet,y))\nFinalSet <- IntSet\n\n# === Split ====\nset.seed(42)\nspt <- sample.split(FinalSet$y, .75)\ntrain <- subset(FinalSet, spt == T)\ntest  <- subset(FinalSet, spt == F)\n\n# Train glm model using glm\nLogMod <- glm(y ~ ., data = train, family = 'binomial')\npred <- predict(LogMod, newdata = test[,1:13], type = 'response')\npred[pred>.5] = 1\npred[pred<.5] = 0\nmax(table(pred == test$y))/nrow(test)\n\n\nwrite.csv(train, file = \"finalset_cleaned_X.csv\", row.names = F)\nwrite.csv(test,  file = \"finalset_cleaned_Y.csv\", row.names = F)",
    "created" : 1449807469310.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2520997306",
    "id" : "85B5B1F8",
    "lastKnownWriteTime" : 1449965446,
    "path" : "F:/Dropbox/Fordham/Fall 2015/CISC 5800 - MACHINE LEARNING/Final Project/Adult/DataCleaning.R",
    "project_path" : "DataCleaning.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}